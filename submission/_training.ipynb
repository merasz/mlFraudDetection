{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba20361",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Training-a-Classifier-to-Detect-Fraudulent-Financial-Transactions\" data-toc-modified-id=\"Training-a-Classifier-to-Detect-Fraudulent-Financial-Transactions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Training a Classifier to Detect Fraudulent Financial Transactions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-the-Test-Set\" data-toc-modified-id=\"Creating-the-Test-Set-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Creating the Test Set</a></span></li><li><span><a href=\"#Fitting-a-Dummy-Classifier\" data-toc-modified-id=\"Fitting-a-Dummy-Classifier-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Fitting a Dummy Classifier</a></span></li><li><span><a href=\"#Training-the-model\" data-toc-modified-id=\"Training-the-model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Training the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Neural-Network\" data-toc-modified-id=\"Neural-Network-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Neural Network</a></span></li></ul></li><li><span><a href=\"#Implementing-the-Predict-Function\" data-toc-modified-id=\"Implementing-the-Predict-Function-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Implementing the Predict Function</a></span></li><li><span><a href=\"#Testing-the-Classifier\" data-toc-modified-id=\"Testing-the-Classifier-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Testing the Classifier</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec369b4e",
   "metadata": {},
   "source": [
    "# Training a Classifier to Detect Fraudulent Financial Transactions\n",
    "First, we load our dataset. Note that due to privacy concerns, all features but for Time and Amount have generic names and were found through [PCA](https://en.wikipedia.org/wiki/Principal_component_analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02167600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:18:41.906677Z",
     "start_time": "2021-04-01T11:18:38.909173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Feature0</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature20</th>\n",
       "      <th>Feature21</th>\n",
       "      <th>Feature22</th>\n",
       "      <th>Feature23</th>\n",
       "      <th>Feature24</th>\n",
       "      <th>Feature25</th>\n",
       "      <th>Feature26</th>\n",
       "      <th>Feature27</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12187.0</td>\n",
       "      <td>1.127257</td>\n",
       "      <td>0.170387</td>\n",
       "      <td>1.675702</td>\n",
       "      <td>1.662017</td>\n",
       "      <td>-1.093046</td>\n",
       "      <td>-0.447651</td>\n",
       "      <td>-0.590031</td>\n",
       "      <td>-0.071291</td>\n",
       "      <td>2.015259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170890</td>\n",
       "      <td>0.009832</td>\n",
       "      <td>0.066699</td>\n",
       "      <td>0.877103</td>\n",
       "      <td>0.350030</td>\n",
       "      <td>-0.482569</td>\n",
       "      <td>0.052777</td>\n",
       "      <td>0.038219</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149717.0</td>\n",
       "      <td>-0.723098</td>\n",
       "      <td>-1.307087</td>\n",
       "      <td>1.119492</td>\n",
       "      <td>-2.486829</td>\n",
       "      <td>-1.781857</td>\n",
       "      <td>0.382495</td>\n",
       "      <td>0.221389</td>\n",
       "      <td>-0.021550</td>\n",
       "      <td>-1.964369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.457047</td>\n",
       "      <td>-0.980797</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>-0.488353</td>\n",
       "      <td>0.336841</td>\n",
       "      <td>-0.335149</td>\n",
       "      <td>-0.027314</td>\n",
       "      <td>-0.226558</td>\n",
       "      <td>299.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72288.0</td>\n",
       "      <td>1.357358</td>\n",
       "      <td>-0.802677</td>\n",
       "      <td>1.135552</td>\n",
       "      <td>-0.490788</td>\n",
       "      <td>-1.672022</td>\n",
       "      <td>-0.509976</td>\n",
       "      <td>-1.192288</td>\n",
       "      <td>0.044009</td>\n",
       "      <td>-0.001600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299976</td>\n",
       "      <td>0.911314</td>\n",
       "      <td>-0.096112</td>\n",
       "      <td>0.427782</td>\n",
       "      <td>0.436567</td>\n",
       "      <td>-0.044389</td>\n",
       "      <td>0.045821</td>\n",
       "      <td>0.024275</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168435.0</td>\n",
       "      <td>1.891806</td>\n",
       "      <td>-0.123111</td>\n",
       "      <td>-1.791275</td>\n",
       "      <td>0.342303</td>\n",
       "      <td>0.235308</td>\n",
       "      <td>-0.723866</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>-0.114664</td>\n",
       "      <td>0.767009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186402</td>\n",
       "      <td>-0.408728</td>\n",
       "      <td>0.091938</td>\n",
       "      <td>-0.518938</td>\n",
       "      <td>-0.082267</td>\n",
       "      <td>-0.088265</td>\n",
       "      <td>-0.015244</td>\n",
       "      <td>-0.022998</td>\n",
       "      <td>61.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55416.0</td>\n",
       "      <td>-0.378806</td>\n",
       "      <td>0.449422</td>\n",
       "      <td>0.154983</td>\n",
       "      <td>-0.899310</td>\n",
       "      <td>-0.678177</td>\n",
       "      <td>-1.419243</td>\n",
       "      <td>0.130648</td>\n",
       "      <td>0.087002</td>\n",
       "      <td>0.509679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053215</td>\n",
       "      <td>0.266919</td>\n",
       "      <td>0.514422</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>-1.279881</td>\n",
       "      <td>-0.166479</td>\n",
       "      <td>0.071403</td>\n",
       "      <td>0.150137</td>\n",
       "      <td>27.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  \\\n",
       "0   12187.0  1.127257  0.170387  1.675702  1.662017 -1.093046 -0.447651   \n",
       "1  149717.0 -0.723098 -1.307087  1.119492 -2.486829 -1.781857  0.382495   \n",
       "2   72288.0  1.357358 -0.802677  1.135552 -0.490788 -1.672022 -0.509976   \n",
       "3  168435.0  1.891806 -0.123111 -1.791275  0.342303  0.235308 -0.723866   \n",
       "4   55416.0 -0.378806  0.449422  0.154983 -0.899310 -0.678177 -1.419243   \n",
       "\n",
       "   Feature6  Feature7  Feature8  ...  Feature20  Feature21  Feature22  \\\n",
       "0 -0.590031 -0.071291  2.015259  ...  -0.170890   0.009832   0.066699   \n",
       "1  0.221389 -0.021550 -1.964369  ...  -0.457047  -0.980797   0.006519   \n",
       "2 -1.192288  0.044009 -0.001600  ...   0.299976   0.911314  -0.096112   \n",
       "3  0.082800 -0.114664  0.767009  ...  -0.186402  -0.408728   0.091938   \n",
       "4  0.130648  0.087002  0.509679  ...   0.053215   0.266919   0.514422   \n",
       "\n",
       "   Feature23  Feature24  Feature25  Feature26  Feature27  Amount  Class  \n",
       "0   0.877103   0.350030  -0.482569   0.052777   0.038219    4.99      0  \n",
       "1  -0.488353   0.336841  -0.335149  -0.027314  -0.226558  299.00      0  \n",
       "2   0.427782   0.436567  -0.044389   0.045821   0.024275   10.00      0  \n",
       "3  -0.518938  -0.082267  -0.088265  -0.015244  -0.022998   61.19      0  \n",
       "4   0.412200  -1.279881  -0.166479   0.071403   0.150137   27.75      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "path = \"/data/mlproject21\" if os.path.exists(\"/data/mlproject21\") else \".\"\n",
    "df = pd.read_csv(os.path.join(path, \"transactions.csv.zip\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e41e6",
   "metadata": {},
   "source": [
    "## Creating the Test Set\n",
    "We perform a split into a train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3456a34b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:18:42.477916Z",
     "start_time": "2021-04-01T11:18:41.909233Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182276 train samples\n",
      " 45569 test samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = \"Class\"),\n",
    "                                                    df[\"Class\"],\n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify = df[\"Class\"])\n",
    "print(f\"{y_train.size} train samples\\n {y_test.size} test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd13449",
   "metadata": {},
   "source": [
    "## Fitting a Dummy Classifier\n",
    "For now, we use a dummy classifier where no matter the input, the probability of reporting a fraudulent transaction is always equal to the ratio of fraudulent transactions in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddf71a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:18:42.516336Z",
     "start_time": "2021-04-01T11:18:42.481724Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c07d1c",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de99f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, filename='model.sav'):\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "def load_model(filename='model.sav'):\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5bc22",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "707b0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    \"\"\"\n",
    "    Basic classifier defining methods train and predict.\n",
    "    This class does no classifications. Use Sub-classes instead\n",
    "    \"\"\"\n",
    "    def train(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5667e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "class LogisticRegression(Classifier):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"\n",
    "        Function that computes the sigmoid of the input values.\n",
    "\n",
    "        :param z: input values\n",
    "        :returns: sigmoid values for each input value\n",
    "        \"\"\"\n",
    "\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def loss_function_gradient(self, w, x, y):\n",
    "        \"\"\"\n",
    "        Function that computes the empirical loss for a logistic regression model.\n",
    "\n",
    "        :param w: Weights vector\n",
    "        :param x: Training input data\n",
    "        :param y: Training target labels\n",
    "        :returns: gradient of the loss\n",
    "        \"\"\"\n",
    "\n",
    "        N = y.shape[0]\n",
    "\n",
    "        f_x = self.sigmoid(x @ w)\n",
    "\n",
    "        gradient = np.dot(x.T, (f_x - y)) / N \n",
    "\n",
    "        return gradient\n",
    "\n",
    "    def batch_gradient_descent(self, x, y, alpha=0.01, num_steps=2000):\n",
    "        \"\"\"\n",
    "        Implementation of the gradient descent algorithm for logistic regression\n",
    "\n",
    "        :param: x: Training input data\n",
    "        :param: y: Training target labels\n",
    "        :param: alpha: Scalar learning rate\n",
    "        :param: num_steps: Number of gradient descent steps\n",
    "        :returns: weight vector 'w'\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize the weights to zero\n",
    "        w = np.zeros((x.shape[1]))\n",
    "\n",
    "        for i in trange(num_steps):\n",
    "            w = w - alpha * self.loss_function_gradient(w, x, y)\n",
    "\n",
    "        return w\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.w = self.batch_gradient_descent(X, y)\n",
    "        print(\"Finished training\")\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Assign input to a class using the logistic regression model.\n",
    "\n",
    "        :param: w: Weight vector\n",
    "        :param: x: Test input data\n",
    "        :returns: Predicted class labels (0 or 1)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.w is None:\n",
    "            print(\"Weights not specified. Train the model first\")\n",
    "            return\n",
    "\n",
    "        f_x = self.sigmoid(x @ self.w)\n",
    "        predictions = np.round(f_x)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d11d33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LogisticRegression():\n",
    "    \"\"\"\n",
    "    Trains a LogisticRegression model using RandomOverSampler and the LogisticRegression class.\n",
    "    :returns: the standardScaler and the trained model\n",
    "    \"\"\"\n",
    "    clf = LogisticRegression()\n",
    "    standardScaler = StandardScaler()\n",
    "\n",
    "    X, y = RandomUnderSampler().fit_resample(X_train, y_train)\n",
    "    X = standardScaler.fit_transform(X, y)\n",
    "\n",
    "    clf.train(X, y)\n",
    "    \n",
    "    return standardScaler, clf\n",
    "\n",
    "# UNCOMMENT this line if you want to train the logistic regression model (Neural Network is preferred) \n",
    "# scaler, clf = train_LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c72e8229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save standardscaler and model\n",
    "\n",
    "# SCALER_NAME = 'scaler.sav'\n",
    "\n",
    "# save_model(scaler, filename=SCALER_NAME)\n",
    "# save_model(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6a8ec",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "212000a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu available: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check https://pytorch.org/docs/stable/notes/randomness.html#reproducibility\n",
    "torch.manual_seed(123)\n",
    "print(\"gpu available:\", torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fdd3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "LEARNING_RATE = 0.0002\n",
    "INPUT_SIZE = 30\n",
    "HIDDEN_SIZE = 11\n",
    "OUTPUT_SIZE = 1\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "MODEL_NAME = 'model.pt'\n",
    "SCALER_NAME = 'scaler.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea24723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input x keeping the batch dimension the same\n",
    "        # Use the relu activation functions \n",
    "        # Pass x through functions but do not apply any activation function\n",
    "        \n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x  # Return x (logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e7011ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of the predicted values y_pred in comparison to y_test.\n",
    "    :returns: the accuracy\n",
    "    \"\"\"\n",
    "    predictions = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (predictions == y_test).sum().float()\n",
    "    acc = correct_results_sum / y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3326c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_neural_network_pytorch(net, train_loader, optimizer, criterion, num_epochs):\n",
    "    \"\"\"\n",
    "    Function for training the PyTorch network.\n",
    "    \n",
    "    :param net: the neural network object\n",
    "    :param inputs: numpy array of training data values\n",
    "    :param labels: numpy array of training data labels \n",
    "    :param optimizer: PyTorch optimizer instance\n",
    "    :param criterion: PyTorch loss function\n",
    "    :param iterations: number of training steps\n",
    "    \"\"\"    \n",
    "    net.train()  # Before training, set the network to training mode\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader)):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels = labels.unsqueeze(1).to(device)\n",
    "\n",
    "            # 1. Zero parameter gradients\n",
    "            # 2. Forward\n",
    "            # 3. Compute loss\n",
    "            # 4. Backward\n",
    "            # 5. Update step\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # calculate current accuracy\n",
    "            acc = binary_acc(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            if batch_idx % 1000 == 999:\n",
    "                print(f'Loss: {loss.item():.5f}')\n",
    "            \n",
    "        print(f'Epoch {epoch}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "        \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5612c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "net = Net(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "net = net.to(device)\n",
    "\n",
    "# Define the loss criterion and the training algorithm\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)  # binary cross entropy\n",
    "\n",
    "# Using Adam optimizer instead of SGD\n",
    "# Adam was faster converging to the (nearly) optimum\n",
    "# Adam Optimizer does not need a momentum\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bf18658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class trainData(Dataset):\n",
    "    \"\"\"\n",
    "    Basic class to store a dataset as torch-Dataset that can be used for torch epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfe23763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9f7670e4a740529df657ce72c3404c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2844.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15573\n",
      "Loss: 0.05282\n",
      "\n",
      "Epoch 0: | Loss: 0.19045 | Acc: 92.044\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1df13272ed14ee98ccbd4324789991e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2844.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.01943\n",
      "Loss: 0.05768\n",
      "\n",
      "Epoch 1: | Loss: 0.06137 | Acc: 97.753\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_nn():\n",
    "    \"\"\"\n",
    "    Preprocesses data, transforms data to torch datasets and starts training the NN-model.\n",
    "    \"\"\"\n",
    "    X, y = SMOTE(random_state=12).fit_resample(X_train.values, y_train.values.ravel())\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X, y)\n",
    "\n",
    "    train_data = trainData(torch.FloatTensor(X), \n",
    "                           torch.FloatTensor(y))\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    # Train the PyTorch network\n",
    "    train_neural_network_pytorch(net, train_loader, optimizer, criterion, NUM_EPOCHS)\n",
    "    \n",
    "    return scaler\n",
    "    \n",
    "scaler = train_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e367502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save standardScaler\n",
    "save_model(scaler, filename=SCALER_NAME)\n",
    "# save nn-model\n",
    "torch.save(net, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad1a5c6",
   "metadata": {},
   "source": [
    "## Implementing the Predict Function\n",
    "You will have to implement the predict function that we will run in order to check the performance of your model on a secret test set. The better you perfrom, the higher you'll be on the leaderboard! For now, our solution is to use our dummy classifier to make predictions based on the input values.\n",
    "\n",
    "Note that this predict function should return the value of the decision function of your model for each transaction in `values`. In the probabilistic case, these are the probabilities that the input values are of target class 1 (i.e. fraud). The higher the value of the decision function, the more likely that a transaction is fraudulent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "069e8278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:18:42.530734Z",
     "start_time": "2021-04-01T11:18:42.523011Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# standardscalar for scaling the data (preprocessing)\n",
    "scaler = load_model(filename=SCALER_NAME)\n",
    "net = torch.load(MODEL_NAME, map_location='cpu')\n",
    "\n",
    "def leader_board_predict_fn(values):\n",
    "    \n",
    "    decision_function_values = np.zeros(values.shape[0])\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    X = scaler.transform(values.values.astype(np.float32))\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    # Make predictions (class 0 or 1) using the learned parameters\n",
    "    \n",
    "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
    "    X = torch.tensor(X)\n",
    "    logits = net(X)\n",
    "    # class 0 if < 0.5, class 1 if >= 0.5 and <= 1\n",
    "    predictions = torch.round(torch.sigmoid(logits))\n",
    "    \n",
    "    decision_function_values = predictions.int().numpy()\n",
    "    decision_function_values = decision_function_values.ravel()\n",
    "    \n",
    "    return decision_function_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e2785c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT the cell and comment the cell above if you want to test LogisticRegression\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # standardscalar for scaling the data (preprocessing)\n",
    "# scaler = load_model(filename=SCALER_NAME)\n",
    "# clf = load_model()\n",
    "\n",
    "# def leader_board_predict_fn(values):\n",
    "#     # YOUR CODE HERE\n",
    "#     values = scaler.transform(values)\n",
    "#     return clf.predict(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8be1f3",
   "metadata": {},
   "source": [
    "## Testing the Classifier\n",
    "To measure the classifier's performance on the test set, we will use the [ROC AUC score](https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics). The best possible score is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6dc1c2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:18:42.558259Z",
     "start_time": "2021-04-01T11:18:42.534795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaderboard Score: 0.94423409234468\n"
     ]
    }
   ],
   "source": [
    "### LEADER BOARD TEST\n",
    "from sklearn.metrics import roc_auc_score\n",
    "score = roc_auc_score(y_test, leader_board_predict_fn(X_test))\n",
    "print(f\"Leaderboard Score: {score}\")\n",
    "### LEADER BOARD TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe13a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "201.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
